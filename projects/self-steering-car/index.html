<!doctype html><html lang=en><head><title>Self-Steering Car · Sharven Prasad Dhanasekar</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta http-equiv=content-security-policy content="upgrade-insecure-requests; block-all-mixed-content; default-src 'self'; child-src 'self'; font-src 'self' https://fonts.gstatic.com https://cdn.jsdelivr.net/; form-action 'self'; frame-src 'self'; img-src 'self'; object-src 'none'; style-src 'self' 'unsafe-inline' https://fonts.googleapis.com/ https://cdn.jsdelivr.net/; script-src 'self' 'unsafe-inline' https://www.google-analytics.com https://cdn.jsdelivr.net/; prefetch-src 'self'; connect-src 'self' https://www.google-analytics.com;"><meta name=author content="Sharven Prasad Dhanasekar"><meta name=description content="An AI agent trained with Reinforcement Learning to steer along any track."><meta name=keywords content="programmer,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Self-Steering Car"><meta name=twitter:description content="An AI agent trained with Reinforcement Learning to steer along any track."><meta property="og:title" content="Self-Steering Car"><meta property="og:description" content="An AI agent trained with Reinforcement Learning to steer along any track."><meta property="og:type" content="article"><meta property="og:url" content="https://sharvenp.github.io/projects/self-steering-car/"><meta property="article:section" content="projects"><meta property="article:published_time" content="2019-06-19T00:00:00+00:00"><meta property="article:modified_time" content="2019-06-19T00:00:00+00:00"><link rel=canonical href=https://sharvenp.github.io/projects/self-steering-car/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.c4d7e93a158eda5a65b3df343745d2092a0a1e2170feeec909b8a89443903c6a.css integrity="sha256-xNfpOhWO2lpls980N0XSCSoKHiFw/u7JCbiolEOQPGo=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css integrity="sha256-OeQafxa9+MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.102.3"></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>Sharven Prasad Dhanasekar</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a>
|</li><li class=navigation-item><a class=navigation-link href=/projects/>Projects</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://sharvenp.github.io/projects/self-steering-car/>Self-Steering Car</a></h1></div><div class=post-meta><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/machine-learning/>machine learning</a></span>
<span class=separator>•</span>
<span class=tag><a href=/tags/python/>python</a></span></div></div></header><div><p>Developed an AI agent that learned how to steer a car along a randomly generated race track using Reinforcement Learning.</p><p>Reinforcement Learning is the process of training an agent to complete a task purely by supplying it rewards/punishment. If the agent does something that is desired, it receives a positive reward, and alternatively, if it does something that isn&rsquo;t desired, it receives a negative reward.</p><p>This may sound familiar, and that&rsquo;s because this is exactly how animals and humans learn!</p><p>With a lot of Statistics and Calculus, we can convert this idea to train an AI agent in a similar fashion to steer a virtual track. Essentially, if the AI reaches the end of the track, it receives a large positive reward, and if it hits the edge of the track, it receives a negative reward.</p><p>There are many algorithms out there to perform Reinforcement Learning and the algorithm used in the project is called <a href=https://towardsdatascience.com/policy-gradients-in-a-nutshell-8b72f9743c5d>Policy Gradients</a> (I used a vanilla version for this project). In a nutshell, it tries to search for an optimal policy which will dictate its actions at certain states and it will do this by exploring random moves. As it explores random moves, it will run into many different scenarios that result in different rewards and by doing this repeatedly, it will gain a sense of what the optimal policy is.</p><p>Learn more about the project at this <a href=https://github.com/sharvenp/self-steering-car>GitHub repository</a>.</p><p>After running the simulation 6000 times, here is how the AI agent performs on a track I drew in paint:</p><div style=text-align:center><img width=600 src=/images/projects/self-steer/self_steer.gif alt="AI agent steering car along track after training 6000 times"></div><p>Some next steps would be to load this model onto a Raspberry Pi and have it control a small toy car using ultrasonic sensors.</p></div><footer></footer></article></section></div><footer class=footer><section class=container>©
2018 -
2022
Sharven Prasad Dhanasekar
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js integrity="sha256-I2BJOV3DaC+ycZZAhylY4S8fJAZ7sJwyeyM+YpDH7aw="></script></body></html>